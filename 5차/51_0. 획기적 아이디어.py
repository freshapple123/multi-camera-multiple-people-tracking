"""
ë‚´ ìƒê°ì—ëŠ” ë‹¤ë¥¸ ê°ë„ì—ì„œì˜ ì‚¬ëŒì„ ì°¾ì„ë•Œ ë§ì•¼,
ë‹¤ë¥¸ ê°ë„ì˜ ì¹´ë©”ë¼ì„œ ê³„ì†í•´ì„œ ì„œë¡œ ìœ ì‚¬ë„ë¥¼ ê²€ì‚¬í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼
ì²¨ì— ì œì¼ ë¹„ìŠ·í•œ ì‚¬ëŒì´ ìˆìœ¼ë©´ idë²ˆí˜¸ë§Œ ë„˜ê²¨ì£¼ê³ 
ë‚˜ì¤‘ì— íŠ¸ë ˆí‚¹ ë° re-id í•˜ëŠ”ê±´ ê°ì ê°ë„ì˜ íˆìŠ¤í† ìœ ì‚¬ë„ê²€ì‚¬ë¡œ
ì›ë˜ í•˜ë“¯ì´ ê³„ì† íŠ¸ë ˆí‚¹ í•˜ëŠ”ê±°ì§€
ê·¸ëŸ¬ë©´ ë¹„ìŠ·í•œ ì‚¬ëŒì´ ìˆì–´ë„ ê³„ì† separateì‹œí‚¬ ìˆ˜ ìˆì„ê±°ê³ 
re-idë¶€ì—¬ë„ ì¢‹ì„ë“¯

"""

import os
import cv2
from ultralytics import YOLO
import numpy as np

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# -------------------- ì„¤ì • --------------------
COMPARE_INTERVAL = 30  # ì•½ 3ì´ˆë§ˆë‹¤ cross-camera ID ë¹„êµ ìˆ˜í–‰ (30fps ê¸°ì¤€)
SIMILARITY_THRESHOLD = 0.4  # ìœ ì‚¬ë„ ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì´ë©´ ë™ì¼ ì¸ë¬¼ë¡œ íŒë‹¨)
SIMILARITY_WEIGHTS = {
    "up": 0.3,  # ìƒì²´ ì˜ì—­ íˆìŠ¤í† ê·¸ë¨ ê°€ì¤‘ì¹˜
    "low": 0.3,  # í•˜ì²´ ì˜ì—­ íˆìŠ¤í† ê·¸ë¨ ê°€ì¤‘ì¹˜
    "full": 0.2,  # ì „ì²´ ëª¸í†µ íˆìŠ¤í† ê·¸ë¨ ê°€ì¤‘ì¹˜
    "hair": 0.2,  # ë¨¸ë¦¬ ì˜ì—­ íˆìŠ¤í† ê·¸ë¨ ê°€ì¤‘ì¹˜
}


# -------------------- í•¨ìˆ˜ ì •ì˜ --------------------


def extract_hs_histogram_from_cropped(cropped_img):
    # ì´ë¯¸ì§€ì˜ ìƒ‰ìƒ ì •ë³´ë¥¼ HSVë¡œ ë³€í™˜í•œ í›„, H-S ì±„ë„ ê¸°ì¤€ 2D íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
    hsv = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2HSV)
    hist = cv2.calcHist(
        [hsv], [0, 1], None, [50, 60], [0, 180, 0, 256]
    )  # H: 50 bins, S: 60 bins
    cv2.normalize(hist, hist)  # ì •ê·œí™”í•˜ì—¬ ì¡°ëª…ì´ë‚˜ í¬ê¸°ì— ëœ ë¯¼ê°í•˜ê²Œ ë§Œë“¦
    return hist.flatten()  # 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•´ ë°˜í™˜


def compare_histograms(hist1, hist2):
    # ë‘ íˆìŠ¤í† ê·¸ë¨ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ìƒê´€ê³„ìˆ˜(CORREL) ë°©ì‹ìœ¼ë¡œ ë¹„êµ
    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)


def get_hist_average(histories, alpha=0.2):
    # ê³¼ê±° íˆìŠ¤í† ë¦¬ë“¤ì„ ì§€ìˆ˜í‰ê·  ë°©ì‹ìœ¼ë¡œ ìŠ¤ë¬´ë”© (ìµœê·¼ íˆìŠ¤í† ë¦¬ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬)
    if len(histories) == 0:
        return None
    smoothed_hist = histories[0]
    for hist in histories[1:]:
        smoothed_hist = alpha * hist + (1 - alpha) * smoothed_hist  # ì§€ìˆ˜ ê°€ì¤‘ í‰ê· 
    return smoothed_hist


def get_valid_points(kp_array, person_idx, indices, threshold=0.5):
    # ì‹ ë¢°ë„(threshold) ì´ìƒì¸ keypointë“¤ë§Œ ì¶”ì¶œí•´ì„œ ë°˜í™˜
    points = []
    for idx in indices:
        x, y, conf = kp_array[person_idx][idx]
        if conf >= threshold:
            points.append([x, y])
    return np.array(points)


def get_cropped_histogram(points, frame):
    # ì£¼ì–´ì§„ keypointë“¤ ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ bounding box ë§Œë“¤ê³ , í•´ë‹¹ ì˜ì—­ì˜ HS íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
    if len(points) < 3:
        return None, None  # ìµœì†Œ 3ì  ì´ìƒ ìˆì–´ì•¼ ì˜ë¯¸ ìˆëŠ” ì˜ì—­ì´ë¼ íŒë‹¨
    x_min, x_max = int(np.min(points[:, 0])), int(np.max(points[:, 0]))
    y_min, y_max = int(np.min(points[:, 1])), int(np.max(points[:, 1]))
    h, w, _ = frame.shape
    x_min, x_max = max(x_min, 0), min(x_max, w)
    y_min, y_max = max(y_min, 0), min(y_max, h)
    cropped_img = frame[y_min:y_max, x_min:x_max]
    hist = extract_hs_histogram_from_cropped(cropped_img)  # ì˜ë¼ë‚¸ ì˜ì—­ì˜ HS íˆìŠ¤í† ê·¸ë¨
    center_x, center_y = int(np.mean(points[:, 0])), int(
        np.mean(points[:, 1])
    )  # ì¤‘ì‹¬ ì¢Œí‘œë„ í•¨ê»˜ ë°˜í™˜
    return hist, (center_x, center_y)


def get_full_body_histogram(kp_array, person_idx, frame):
    # 17ê°œì˜ ëª¨ë“  keypointë¥¼ ì´ìš©í•´ ì „ì²´ ëª¸ ì˜ì—­ bounding box ê³„ì‚° í›„ íˆìŠ¤í† ê·¸ë¨ ì¶”ì¶œ
    full_points = get_valid_points(kp_array, person_idx, list(range(17)))
    if len(full_points) < 5:
        return None  # ì „ì²´ ëª¸ ì¸ì‹ì´ ì œëŒ€ë¡œ ì•ˆ ëœ ê²½ìš°ëŠ” ì œì™¸
    x_min, x_max = int(np.min(full_points[:, 0])), int(np.max(full_points[:, 0]))
    y_min, y_max = int(np.min(full_points[:, 1])), int(np.max(full_points[:, 1]))
    h, w, _ = frame.shape
    x_min, x_max = max(x_min, 0), min(x_max, w)
    y_min, y_max = max(y_min, 0), min(y_max, h)
    cropped_img = frame[y_min:y_max, x_min:x_max]
    return extract_hs_histogram_from_cropped(cropped_img)


def get_hair_histogram(kp_array, person_idx, frame):
    # ì–¼êµ´ê³¼ ì–´ê¹¨ keypointë¥¼ í™œìš©í•˜ì—¬ ë¨¸ë¦¬ ë¶€ë¶„ ì˜ì—­ì„ ì˜ë¼ë‚´ê³  HS íˆìŠ¤í† ê·¸ë¨ì„ ì¶”ì¶œ
    keypoints = kp_array[person_idx]
    # ì™¼ëˆˆ, ì˜¤ë¥¸ëˆˆ, ì™¼ì–´ê¹¨, ì˜¤ë¥¸ì–´ê¹¨, ì½” ë“±ì˜ keypoint ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ì œì™¸
    if np.any(keypoints[[0, 1, 2, 5, 6], 2] < 0.5):
        return None

    # ëˆˆê³¼ ì–´ê¹¨ ì¢Œí‘œ ì¶”ì¶œ
    left_eye, right_eye = keypoints[1][:2], keypoints[2][:2]
    left_shoulder, right_shoulder = keypoints[5][:2], keypoints[6][:2]

    # ë¨¸ë¦¬ ì˜ì—­ì˜ bounding box ì¢Œí‘œ ê³„ì‚° (ëˆˆ ìœ„ìª½ë¶€í„° ì–´ê¹¨ ìœ„ê¹Œì§€)
    x_min = int(min(left_eye[0], right_eye[0]) - 30)
    x_max = int(max(left_eye[0], right_eye[0]) + 30)
    y_top = int(min(left_eye[1], right_eye[1]) - 30)
    y_bottom = int(min(left_shoulder[1], right_shoulder[1]) - 10)

    h, w, _ = frame.shape
    x_min, x_max = max(x_min, 0), min(x_max, w)
    y_top, y_bottom = max(y_top, 0), min(y_bottom, h)

    # ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ì—­ì´ë©´ None ë°˜í™˜
    if y_bottom <= y_top or x_max <= x_min:
        return None

    # ë¨¸ë¦¬ ì˜ì—­ ì˜ë¼ë‚´ê¸°
    cropped = frame[y_top:y_bottom, x_min:x_max]
    return extract_hs_histogram_from_cropped(cropped)


def get_angle_path(n):
    # ì…ë ¥ëœ ìˆ«ì(n)ì— ë”°ë¼ në²ˆì§¸ ê°ë„ì˜ ì˜ìƒ ê²½ë¡œë¥¼ ë°˜í™˜
    angle_str = (
        f"{n}st" if n == 1 else f"{n}nd" if n == 2 else f"{n}rd" if n == 3 else f"{n}th"
    )
    return rf"D:\\REid\\data\\retail\\MMPTracking_training\\To_seperate_for_video\\{angle_str}_angle\\{angle_str}_angle.mp4"


def compute_similarity(hist1, hist2):
    # ë‘ íˆìŠ¤í† ê·¸ë¨ì´ ìœ íš¨í•œ ê²½ìš° ìœ ì‚¬ë„ ê³„ì‚°, ì•„ë‹ˆë¼ë©´ None ë°˜í™˜
    if hist1 is None or hist2 is None:
        return None
    return compare_histograms(hist1, hist2)


def cross_camera_matching():
    global person_db, global_id_map, next_global_id  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©

    # ê° ì¹´ë©”ë¼ì—ì„œ ì¶”ì¶œëœ ì‚¬ëŒ ë°ì´í„°
    cam1_db = person_db["cam1"]
    cam2_db = person_db["cam2"]

    similarity_matrix = {}  # (cam1_id, cam2_id) â†’ ìœ ì‚¬ë„ ì €ì¥

    # -------------------- ëª¨ë“  ID ìŒì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚° --------------------
    for id1, data1 in cam1_db.items():
        for id2, data2 in cam2_db.items():
            sim_dict = {}  # ìƒì²´, í•˜ì²´, ì „ì²´, ë¨¸ë¦¬ ë³„ ìœ ì‚¬ë„ ì €ì¥

            # ê° ë¶€ìœ„ë³„ë¡œ íˆìŠ¤í† ë¦¬ ì¡´ì¬í•  ê²½ìš° ìœ ì‚¬ë„ ê³„ì‚°
            if data1["up_histories"] and data2["up_histories"]:
                sim_dict["up"] = compare_histograms(
                    get_hist_average(data1["up_histories"]),
                    get_hist_average(data2["up_histories"]),
                )
            if data1["low_histories"] and data2["low_histories"]:
                sim_dict["low"] = compare_histograms(
                    get_hist_average(data1["low_histories"]),
                    get_hist_average(data2["low_histories"]),
                )
            if data1["full_histories"] and data2["full_histories"]:
                sim_dict["full"] = compare_histograms(
                    get_hist_average(data1["full_histories"]),
                    get_hist_average(data2["full_histories"]),
                )
            if data1["hair_histories"] and data2["hair_histories"]:
                sim_dict["hair"] = compare_histograms(
                    get_hist_average(data1["hair_histories"]),
                    get_hist_average(data2["hair_histories"]),
                )

            # í•˜ë‚˜ë¼ë„ ìœ ì‚¬ë„ê°€ ìˆìœ¼ë©´ ê°€ì¤‘ í‰ê·  ê³„ì‚°
            if sim_dict:
                sim_values = list(sim_dict.values())  # ìœ ì‚¬ë„ ê°’ ë¦¬ìŠ¤íŠ¸
                weight_values = [
                    SIMILARITY_WEIGHTS[k] for k in sim_dict.keys()
                ]  # í•´ë‹¹ ë¶€ìœ„ ê°€ì¤‘ì¹˜
                similarity = np.average(sim_values, weights=weight_values)
                similarity_matrix[(id1, id2)] = similarity  # ìœ ì‚¬ë„ ì €ì¥

    # -------------------- cam1 â†’ cam2: ê°€ì¥ ìœ ì‚¬í•œ ID --------------------
    best_cam2_for_cam1 = {}
    for (id1, id2), sim in similarity_matrix.items():
        if sim > SIMILARITY_THRESHOLD:  # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ ê³ ë ¤
            # í˜„ì¬ê¹Œì§€ì˜ ìµœê³  ìœ ì‚¬ë„ë³´ë‹¤ ë†’ìœ¼ë©´ ì—…ë°ì´íŠ¸
            if id1 not in best_cam2_for_cam1 or sim > similarity_matrix.get(
                (id1, best_cam2_for_cam1[id1]), -1
            ):
                best_cam2_for_cam1[id1] = id2

    # -------------------- cam2 â†’ cam1: ê°€ì¥ ìœ ì‚¬í•œ ID --------------------
    best_cam1_for_cam2 = {}
    for (id1, id2), sim in similarity_matrix.items():
        if sim > SIMILARITY_THRESHOLD:
            if id2 not in best_cam1_for_cam2 or sim > similarity_matrix.get(
                (best_cam1_for_cam2[id2], id2), -1
            ):
                best_cam1_for_cam2[id2] = id1

    # -------------------- Mutual Best Matching --------------------
    for id1, id2 in best_cam2_for_cam1.items():
        if (
            best_cam1_for_cam2.get(id2) == id1
        ):  # ì„œë¡œê°€ ì„œë¡œë¥¼ ê°€ì¥ ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨í•œ ê²½ìš°
            key1 = f"cam1_{id1}"
            key2 = f"cam2_{id2}"

            # ë‘ ID ëª¨ë‘ ì²˜ìŒ ë§¤ì¹­ë˜ëŠ” ê²½ìš°: ìƒˆ global ID ë¶€ì—¬
            if key1 not in global_id_map and key2 not in global_id_map:
                global_id_map[key1] = next_global_id
                global_id_map[key2] = next_global_id
                print(
                    f"ğŸ” Mutual ë§¤ì¹­ë¨: cam1_{id1} â†” cam2_{id2} â†’ ID: {next_global_id}"
                )
                next_global_id += 1

            # í•œìª½ë§Œ global_idê°€ ìˆìœ¼ë©´ ë‹¤ë¥¸ ìª½ì— ë³µì‚¬
            elif key1 in global_id_map and key2 not in global_id_map:
                global_id_map[key2] = global_id_map[key1]
            elif key2 in global_id_map and key1 not in global_id_map:
                global_id_map[key1] = global_id_map[key2]


# -------------------- ë©”ì¸ ì‹¤í–‰ --------------------

a, b = 1, 5  # ì‚¬ìš©í•  ì¹´ë©”ë¼ ê°ë„ ë²ˆí˜¸ (ì˜ˆ: 1ë²ˆ ê°ë„ì™€ 5ë²ˆ ê°ë„ ë¹„êµ)
video_paths = {
    "cam1": get_angle_path(a),  # cam1 ì˜ìƒ ê²½ë¡œ
    "cam2": get_angle_path(b),  # cam2 ì˜ìƒ ê²½ë¡œ
}

# ê° ë¹„ë””ì˜¤ íŒŒì¼ì„ OpenCV VideoCapture ê°ì²´ë¡œ ë¡œë“œ
caps = {
    "cam1": cv2.VideoCapture(video_paths["cam1"]),
    "cam2": cv2.VideoCapture(video_paths["cam2"]),
}

# YOLOv8 í¬ì¦ˆ ëª¨ë¸ ë¡œë“œ (ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš©)
model = YOLO("yolov8n-pose.pt")

# ì‹ ì²´ ë¶€ìœ„ ì¸ë±ìŠ¤ (keypoint index ê¸°ì¤€)
upper_indices = [5, 6, 11, 12]  # ì–‘ìª½ ì–´ê¹¨ì™€ ì—‰ë©ì´ (ìƒì²´)
lower_indices = [11, 12, 15, 16]  # ì–‘ìª½ ì—‰ë©ì´ì™€ ë°œëª© (í•˜ì²´)

# ê° ì¹´ë©”ë¼ ë³„ ì‚¬ëŒ ì •ë³´ ì €ì¥ ë”•ì…”ë„ˆë¦¬ (íˆìŠ¤í† ë¦¬ í¬í•¨)
person_db = {"cam1": {}, "cam2": {}}

# ê° ì¹´ë©”ë¼ ë³„ ë‹¤ìŒì— ë¶€ì—¬í•  ë¡œì»¬ ID
next_id = {"cam1": 0, "cam2": 0}

# cross-camera í†µí•© ID ë§¤í•‘: "cam1_0" â†’ 1, "cam2_3" â†’ 1 ê°™ì€ í˜•ì‹
global_id_map = {}

# ë‹¤ìŒì— ë¶€ì—¬í•  global ID ë²ˆí˜¸ (mutual match ì‹œ í• ë‹¹ë¨)
next_global_id = 0

# ì „ì²´ í”„ë ˆì„ ì¹´ìš´íŠ¸ (intervalë§ˆë‹¤ cross-camera ë¹„êµìš©)
frame_count = 0

while True:
    frames = {}
    results = {}

    # -------------------- ê° ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ ì½ê³ , YOLO Pose ì¶”ë¡  --------------------
    for cam_name, cap in caps.items():
        ret, frame = cap.read()
        if not ret:
            continue
        frames[cam_name] = frame
        results[cam_name] = model(frame)[0].keypoints  # í¬ì¦ˆ keypoints ì¶”ì¶œ

    if not frames:
        break  # ëª¨ë“  ì¹´ë©”ë¼ í”„ë ˆì„ì´ ëë‚¬ì„ ê²½ìš° ì¢…ë£Œ

    # -------------------- ì¹´ë©”ë¼ë³„ í”„ë ˆì„ ì²˜ë¦¬ --------------------
    for cam_name in frames:
        frame = frames[cam_name]
        keypoints = results[cam_name]
        if keypoints is None or keypoints.data.shape[0] == 0:
            continue  # ì‚¬ëŒ ì¸ì‹ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆëœ€

        kp_array = keypoints.data.cpu().numpy()  # keypointsë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜

        # -------------------- í”„ë ˆì„ ë‚´ ëª¨ë“  ì‚¬ëŒì— ëŒ€í•´ ì²˜ë¦¬ --------------------
        for person_idx in range(len(kp_array)):
            # ìƒì²´/í•˜ì²´ keypoint ì¢Œí‘œ ì¶”ì¶œ
            up_points = get_valid_points(kp_array, person_idx, upper_indices)
            low_points = get_valid_points(kp_array, person_idx, lower_indices)

            # ìƒì²´/í•˜ì²´ histogramê³¼ ì¤‘ì‹¬ì¢Œí‘œ ê³„ì‚°
            up_hist, center_pos = (
                get_cropped_histogram(up_points, frame)
                if len(up_points) >= 3
                else (None, None)
            )
            low_hist, _ = (
                get_cropped_histogram(low_points, frame)
                if len(low_points) >= 3
                else (None, None)
            )

            # ì „ì²´/ë¨¸ë¦¬ histogram ì¶”ì¶œ
            full_hist = get_full_body_histogram(kp_array, person_idx, frame)
            hair_hist = get_hair_histogram(kp_array, person_idx, frame)

            # 4ê°œ ë‹¤ Noneì´ë©´ ë¬´ì‹œ
            if all(h is None for h in [up_hist, low_hist, full_hist, hair_hist]):
                continue

            # -------------------- ê¸°ì¡´ personê³¼ ìœ ì‚¬ë„ ë¹„êµ (re-ID) --------------------
            matched_id = None
            max_similarity = -1
            for pid, data in person_db[cam_name].items():
                sim_dict = {}

                if up_hist is not None and data["up_histories"]:
                    sim_dict["up"] = compare_histograms(
                        up_hist, get_hist_average(data["up_histories"])
                    )
                if low_hist is not None and data["low_histories"]:
                    sim_dict["low"] = compare_histograms(
                        low_hist, get_hist_average(data["low_histories"])
                    )
                if full_hist is not None and data["full_histories"]:
                    sim_dict["full"] = compare_histograms(
                        full_hist, get_hist_average(data["full_histories"])
                    )
                if hair_hist is not None and data["hair_histories"]:
                    sim_dict["hair"] = compare_histograms(
                        hair_hist, get_hist_average(data["hair_histories"])
                    )

                # ìœ ì‚¬ë„ ê°€ì¤‘ í‰ê·  ê³„ì‚°
                if sim_dict:
                    sim_values = list(sim_dict.values())
                    weight_values = [SIMILARITY_WEIGHTS[k] for k in sim_dict.keys()]
                    similarity = np.average(sim_values, weights=weight_values)

                    if similarity > max_similarity:
                        matched_id = pid
                        max_similarity = similarity

            # -------------------- ìƒˆë¡œìš´ ì‚¬ëŒìœ¼ë¡œ ê°„ì£¼ --------------------
            if matched_id is None or max_similarity < SIMILARITY_THRESHOLD:
                matched_id = next_id[cam_name]
                next_id[cam_name] += 1
                person_db[cam_name][matched_id] = {
                    "up_histories": [],
                    "low_histories": [],
                    "full_histories": [],
                    "hair_histories": [],
                    "last_position": center_pos,
                }

            # -------------------- íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ --------------------
            for key, hist in zip(
                ["up", "low", "full", "hair"], [up_hist, low_hist, full_hist, hair_hist]
            ):
                if hist is not None:
                    hist_list = person_db[cam_name][matched_id][f"{key}_histories"]
                    hist_list.append(hist)
                    if len(hist_list) > 20:
                        hist_list.pop(0)  # ìµœëŒ€ 20ê°œê¹Œì§€ë§Œ ì €ì¥ (ë©”ëª¨ë¦¬ ì œí•œ)

            # -------------------- ID ì‹œê°í™” --------------------
            global_key = f"{cam_name}_{matched_id}"
            global_id = global_id_map.get(
                global_key, global_key
            )  # global IDê°€ ìˆìœ¼ë©´ ì¶œë ¥, ì—†ìœ¼ë©´ ë¡œì»¬ ID
            if center_pos is not None:
                cv2.putText(
                    frame,
                    f"ID: {global_id}",
                    center_pos,
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (0, 255, 0),
                    2,
                )

    # -------------------- ê²°ê³¼ í”„ë ˆì„ ë””ìŠ¤í”Œë ˆì´ --------------------
    for cam_name in frames:
        cv2.imshow(f"Tracking - {cam_name}", frames[cam_name])

    # -------------------- ì£¼ê¸°ì ìœ¼ë¡œ cross-camera ë§¤ì¹­ --------------------
    frame_count += 1
    if frame_count % COMPARE_INTERVAL == 0:
        cross_camera_matching()

    # -------------------- ì¢…ë£Œ ì¡°ê±´ --------------------
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# -------------------- ì¢…ë£Œ ì²˜ë¦¬ --------------------
for cap in caps.values():
    cap.release()
cv2.destroyAllWindows()
